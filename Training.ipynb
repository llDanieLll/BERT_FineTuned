{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"CUDA available: \", torch.cuda.is_available())\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DjiyFgIG80uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers datasets evaluate accelerate --upgrade"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ts0iMy5p-2By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")"
      ],
      "metadata": {
        "id": "0GYLGpng-_Lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "ckpt = \"bert-base-uncased\" # base BERT\n",
        "ds = load_dataset(\"glue\", \"sst2\") # SST-2 sentiment dataset\n",
        "tok = AutoTokenizer.from_pretrained(ckpt)\n",
        "\n",
        "def tokenize(batch):\n",
        "  return tok(batch[\"sentence\"], truncation=True, max_length=128)\n",
        "\n",
        "ds_tok = ds.map(tokenize, batched=True, remove_columns=[\"sentence\"])\n"
      ],
      "metadata": {
        "id": "49xtTst3_KSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer\n",
        "import numpy as np, evaluate\n",
        "\n",
        "collator = DataCollatorWithPadding(tokenizer=tok)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(ckpt, num_labels=2)\n",
        "\n",
        "metric = evaluate.load(\"glue\", \"sst2\")\n",
        "def compute_metrics(eval_pred):\n",
        "  logits, labels = eval_pred\n",
        "  preds = np.argmax(logits, axis=-1)\n",
        "  return metric.compute(predictions=preds, references=labels)\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"bert-sst2-t4\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    logging_steps=50,\n",
        "    do_eval=True,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=ds_tok[\"train\"],\n",
        "    eval_dataset=ds_tok[\"validation\"],\n",
        "    tokenizer=tok,\n",
        "    data_collator=collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "4wJYcYA-BF5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()\n",
        "train_result"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Tyol_eY3BtOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = trainer.evaluate()\n",
        "metrics"
      ],
      "metadata": {
        "id": "3_D-lWGAMwTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextClassificationPipeline\n",
        "pipe = TextClassificationPipeline(model=trainer.model, tokenizer=tok, device=0)\n",
        "print(pipe(\"This movie was absolutely fantastic!\"))\n",
        "print(pipe(\"That was the worst meal I've had in years.\"))"
      ],
      "metadata": {
        "id": "OZtQhVebM625"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = \"bert-sst2-t4-best\"\n",
        "trainer.model.save_pretrained(save_dir)\n",
        "tok.save_pretrained(save_dir)"
      ],
      "metadata": {
        "id": "bI2U97Y8P9OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content"
      ],
      "metadata": {
        "id": "rfW2Q05YUG4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name llDanieLll\n",
        "!git config --global user.email danielqiujiahao@gmail.com\n",
        "\n",
        "# Clone your repo (replace with your repo URL)\n",
        "!git clone https://github.com/llDanieLll/BERT_FineTuned.git\n",
        "%cd BERT_FineTuned\n",
        "!cp /content ./bert_sst2_finetune.ipynb\n",
        "\n",
        "with open(\"requirements.txt\",\"w\") as f:\n",
        "  f.write(\"transformers>=4.44\\ndatasets>=2.20\\nevaluate>=0.4\\naccelerate>=0.33\\ntorch\\n\")\n",
        "\n",
        "!git add bert_sst2_finetune.ipynb requirements.txt\n",
        "!git commit -m \"Add Colab notebook and requirements\"\n",
        "\n",
        "!git push"
      ],
      "metadata": {
        "id": "mBDbrcq5Qoyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"Training.ipynb\")"
      ],
      "metadata": {
        "id": "IuPVXpAZWFCf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}